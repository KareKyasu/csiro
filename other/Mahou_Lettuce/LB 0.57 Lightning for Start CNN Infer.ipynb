{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e741cf",
   "metadata": {
    "papermill": {
     "duration": 0.003571,
     "end_time": "2025-11-02T02:34:53.062196",
     "exception": false,
     "start_time": "2025-11-02T02:34:53.058625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A EfficientNet-B2 Based Model Coding in Pytorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c823e2",
   "metadata": {
    "papermill": {
     "duration": 0.00238,
     "end_time": "2025-11-02T02:34:53.067419",
     "exception": false,
     "start_time": "2025-11-02T02:34:53.065039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ§  Model Overview\n",
    "\n",
    "This model was developed for the CSIRO competition using PyTorch Lightning.\n",
    "It leverages a dual-branch architecture designed to process paired image halves and learn their combined representations efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6bf57e",
   "metadata": {
    "papermill": {
     "duration": 0.002423,
     "end_time": "2025-11-02T02:34:53.072365",
     "exception": false,
     "start_time": "2025-11-02T02:34:53.069942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## âš™ï¸ Data Preprocessing\n",
    "\n",
    "Each input image is split in half along the center, and both halves are fed into the model simultaneously.\n",
    "This setup allows the network to capture cross-regional relationships within each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1c024",
   "metadata": {
    "papermill": {
     "duration": 0.002325,
     "end_time": "2025-11-02T02:34:53.077169",
     "exception": false,
     "start_time": "2025-11-02T02:34:53.074844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ—ï¸ Model Architecture\n",
    "\n",
    "The model structure follows this pipeline:\n",
    "\n",
    "2 Ã— EfficientNet-B2 (shared weights) -> Linear -> ReLU -> Linear\n",
    "\n",
    "Only the last block of the EfficientNet backbone is trainable, keeping the remaining layers frozen for stability and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd2127",
   "metadata": {
    "papermill": {
     "duration": 0.002329,
     "end_time": "2025-11-02T02:34:53.081947",
     "exception": false,
     "start_time": "2025-11-02T02:34:53.079618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## âš ï¸ Important Notice\n",
    "\n",
    "Version 2 and Version 1 of the model have different architectures and are not compatible.\n",
    "Please make sure to use the matching training notebook for the correct version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d46a1f",
   "metadata": {
    "papermill": {
     "duration": 0.00231,
     "end_time": "2025-11-02T02:34:53.086774",
     "exception": false,
     "start_time": "2025-11-02T02:34:53.084464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cdc6d84",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-02T02:34:53.092788Z",
     "iopub.status.busy": "2025-11-02T02:34:53.092524Z",
     "iopub.status.idle": "2025-11-02T02:35:14.616027Z",
     "shell.execute_reply": "2025-11-02T02:35:14.615198Z"
    },
    "papermill": {
     "duration": 21.528349,
     "end_time": "2025-11-02T02:35:14.617572",
     "exception": false,
     "start_time": "2025-11-02T02:34:53.089223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# I would like to thank these generous sharings which make this notebook possible:\n",
    "# https://www.kaggle.com/code/easterndundrey/csiro-gold-solution\n",
    "# https://www.kaggle.com/code/easterndundrey/bad-assumptions?scriptVersionId=272451747\n",
    "# https://www.kaggle.com/code/mks2192/csiro-notebook-training\n",
    "# https://www.kaggle.com/code/mks2192/csiro-image2biomass\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dc88e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.624374Z",
     "iopub.status.busy": "2025-11-02T02:35:14.623898Z",
     "iopub.status.idle": "2025-11-02T02:35:14.651227Z",
     "shell.execute_reply": "2025-11-02T02:35:14.650681Z"
    },
    "papermill": {
     "duration": 0.031702,
     "end_time": "2025-11-02T02:35:14.652288",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.620586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Load Datafile ========\n",
    "test_df = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\n",
    "test_df[\"id\"] = test_df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "image_paths_df = test_df[[\"id\",\"image_path\"]].drop_duplicates(\"image_path\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23f8199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.658451Z",
     "iopub.status.busy": "2025-11-02T02:35:14.658211Z",
     "iopub.status.idle": "2025-11-02T02:35:14.669090Z",
     "shell.execute_reply": "2025-11-02T02:35:14.668554Z"
    },
    "papermill": {
     "duration": 0.015118,
     "end_time": "2025-11-02T02:35:14.670122",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.655004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Seed ========\n",
    "def seed_everything(seed: int = 114514):\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5054dcff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.676014Z",
     "iopub.status.busy": "2025-11-02T02:35:14.675834Z",
     "iopub.status.idle": "2025-11-02T02:35:14.681210Z",
     "shell.execute_reply": "2025-11-02T02:35:14.680733Z"
    },
    "papermill": {
     "duration": 0.009501,
     "end_time": "2025-11-02T02:35:14.682241",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.672740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Dataset ========\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df, full_image_aug=None, per_half_transform=None):\n",
    "        self.df = df\n",
    "        self.full_image_aug = full_image_aug\n",
    "        self.per_half_transform = per_half_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open('/kaggle/input/csiro-biomass/' + row[\"image_path\"]).convert(\"RGB\")\n",
    "    \n",
    "        base = self.full_image_aug(image) if self.full_image_aug is not None else image\n",
    "    \n",
    "        left = base.crop((0, 0, 1000, 1000))\n",
    "        right = base.crop((1000, 0, 2000, 1000))\n",
    "    \n",
    "        if self.per_half_transform is not None:\n",
    "            left = self.per_half_transform(left)\n",
    "            right = self.per_half_transform(right)\n",
    "        else:\n",
    "            left = F.to_tensor(left)\n",
    "            right = F.to_tensor(right)\n",
    "    \n",
    "        imgs = torch.stack([left, right], dim=0)   # (2, C, H, W)\n",
    "    \n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed312a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.688260Z",
     "iopub.status.busy": "2025-11-02T02:35:14.687826Z",
     "iopub.status.idle": "2025-11-02T02:35:14.693231Z",
     "shell.execute_reply": "2025-11-02T02:35:14.692662Z"
    },
    "papermill": {
     "duration": 0.009379,
     "end_time": "2025-11-02T02:35:14.694132",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.684753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Loss Funtion ========\n",
    "class WeightedR2Loss(nn.Module):\n",
    "    def __init__(self, weights=None, eps=1e-8):\n",
    "        super().__init__()\n",
    "        if weights is None:\n",
    "            weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5])\n",
    "        self.register_buffer('weights', weights)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: (B, 3)\n",
    "        y_true: (B, 5)\n",
    "        \"\"\"\n",
    "        DG = y_pred[:,0]\n",
    "        GDM = y_pred[:,1]\n",
    "        DT = y_pred[:,2]\n",
    "        DD = DT - GDM\n",
    "        DC = GDM - DG\n",
    "        y_hat = torch.stack([DG, DD, DC, GDM, DT], dim=1)\n",
    "        \n",
    "        y_mean = torch.mean(y_true, dim=0, keepdim=True)\n",
    "        ss_res = torch.sum((y_true - y_hat) ** 2, dim=0)\n",
    "        ss_tot = torch.sum((y_true - y_mean) ** 2, dim=0)\n",
    "        r2 = 1 - ss_res / (ss_tot + self.eps)\n",
    "\n",
    "        weighted_r2 = torch.sum(self.weights * r2)\n",
    "        loss = 1 - weighted_r2\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcda8191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.700241Z",
     "iopub.status.busy": "2025-11-02T02:35:14.700013Z",
     "iopub.status.idle": "2025-11-02T02:35:14.715318Z",
     "shell.execute_reply": "2025-11-02T02:35:14.714603Z"
    },
    "papermill": {
     "duration": 0.019573,
     "end_time": "2025-11-02T02:35:14.716325",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.696752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Model ========\n",
    "class MultiRegressionModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"efficientnet_b2\",\n",
    "        pretrained=False,\n",
    "        lr=5e-3,\n",
    "        output_dim=3,\n",
    "        hidden_dim=1536,\n",
    "        open_last_n_blocks=1,\n",
    "        train_bn=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=0, \n",
    "            global_pool=\"avg\"\n",
    "        )\n",
    "        feat_dim = getattr(self.backbone, \"num_features\", None)\n",
    "        if feat_dim is None:\n",
    "            x_dummy = torch.zeros(1, 3, 1000, 1000)\n",
    "            with torch.no_grad():\n",
    "                feat_dim = self.backbone(x_dummy).shape[-1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(feat_dim * 2, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "\n",
    "        self.criterion = WeightedR2Loss()\n",
    "        self.val_outputs = []\n",
    "        self._freeze_backbone(open_last_n_blocks=open_last_n_blocks, train_bn=train_bn)\n",
    "\n",
    "    # Helpers\n",
    "    def _set_requires_grad(self, module, flag: bool):\n",
    "        for p in module.parameters():\n",
    "            p.requires_grad = flag\n",
    "            \n",
    "    def _freeze_backbone(self, open_last_n_blocks=1, train_bn=False):\n",
    "        self._set_requires_grad(self.backbone, False)\n",
    "\n",
    "        if hasattr(self.backbone, \"blocks\"):\n",
    "            blocks = self.backbone.blocks\n",
    "            n = len(blocks)\n",
    "            assert open_last_n_blocks >= 1 and open_last_n_blocks <= n, \\\n",
    "                f\"Expect open_last_n_blocks between [1, {n}], get {open_last_n_blocks}\"\n",
    "            for blk in blocks[n - open_last_n_blocks:]:\n",
    "                self._set_requires_grad(blk, True)\n",
    "\n",
    "        if not train_bn:\n",
    "            for m in self.backbone.modules():\n",
    "                if isinstance(m, (nn.BatchNorm2d, nn.SyncBatchNorm)):\n",
    "                    if all(not p.requires_grad for p in m.parameters()):\n",
    "                        m.eval()\n",
    "\n",
    "        self._set_requires_grad(self.head, True)\n",
    "\n",
    "\n",
    "    def forward(self, x_imgs):\n",
    "        if x_imgs.ndim == 5:\n",
    "            B, T, C, H, W = x_imgs.shape\n",
    "            assert T == 2, f\"Expect 2 pics, get T={T}\"\n",
    "            x = x_imgs.view(B * T, C, H, W)\n",
    "            feats = self.backbone(x)\n",
    "            F = feats.shape[-1]\n",
    "            feats = feats.view(B, T, F)\n",
    "            fused = torch.cat([feats[:, 0, :], feats[:, 1, :]], dim=1)\n",
    "        elif x_imgs.ndim == 4:\n",
    "            T, C, H, W = x_imgs.shape\n",
    "            assert T == 2, f\"Expect 2 pics, get T={T}\"\n",
    "            feats = self.backbone(x_imgs)\n",
    "            fused = torch.cat([feats[0], feats[1]], dim=0).unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(\"SHAPE should be train/val-(B, 2, C, H, W) or single-sample val-(2, C, H, W)\")\n",
    "\n",
    "        y_hat = self.head(fused)\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_img, y = batch\n",
    "        y_hat = self(x_img)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_img, y = batch\n",
    "        y_hat = self(x_img)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.val_outputs.append((y_hat.detach().cpu(), y.detach().cpu()))\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        y_hats = torch.cat([x[0] for x in self.val_outputs], dim=0)\n",
    "        y_trues = torch.cat([x[1] for x in self.val_outputs], dim=0)\n",
    "        self.val_outputs.clear()\n",
    "\n",
    "        DG = y_hats[:, 0]\n",
    "        GDM = y_hats[:, 1]\n",
    "        DT = y_hats[:, 2]\n",
    "        DD = DT - GDM\n",
    "        DC = GDM - DG\n",
    "        y_hat_full = torch.stack([DG, DD, DC, GDM, DT], dim=1)\n",
    "\n",
    "        y_mean = torch.mean(y_trues, dim=0, keepdim=True)\n",
    "        ss_res = torch.sum((y_trues - y_hat_full) ** 2, dim=0)\n",
    "        ss_tot = torch.sum((y_trues - y_mean) ** 2, dim=0)\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-8)\n",
    "\n",
    "        weights = self.criterion.weights.cpu()\n",
    "        weighted_r2 = torch.sum(weights * r2)\n",
    "\n",
    "        for i, name in enumerate([\"DG\", \"DD\", \"DC\", \"GDM\", \"DT\"]):\n",
    "            self.log(f\"val_r2_{name}\", r2[i], prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_weighted_r2\", weighted_r2, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            threshold=0.001,\n",
    "            min_lr=1e-7,\n",
    "            verbose=False,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6f6e1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.722403Z",
     "iopub.status.busy": "2025-11-02T02:35:14.721895Z",
     "iopub.status.idle": "2025-11-02T02:35:14.725968Z",
     "shell.execute_reply": "2025-11-02T02:35:14.725381Z"
    },
    "papermill": {
     "duration": 0.008065,
     "end_time": "2025-11-02T02:35:14.726979",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.718914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Helpers ========\n",
    "def tta_inference(model, images):\n",
    "    preds = model(images)\n",
    "    preds_lr = model(torch.flip(images, dims=[-1]))\n",
    "    preds_ud = model(torch.flip(images, dims=[-2]))\n",
    "    preds_lrud = model(torch.flip(images, dims=[-1, -2]))\n",
    "    preds_mean = 0.4 * preds + 0.3 * preds_lr + 0.2 * preds_ud + 0.1 * preds_lrud\n",
    "    return preds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e338c2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.732882Z",
     "iopub.status.busy": "2025-11-02T02:35:14.732684Z",
     "iopub.status.idle": "2025-11-02T02:35:14.736812Z",
     "shell.execute_reply": "2025-11-02T02:35:14.736298Z"
    },
    "papermill": {
     "duration": 0.008155,
     "end_time": "2025-11-02T02:35:14.737750",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.729595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== DataLoader ========\n",
    "# Transform\n",
    "img_size = 1000\n",
    "infer_transform = T.Compose([\n",
    "    T.Resize((img_size, img_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406],\n",
    "                [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# DataLoader\n",
    "dataset = InferenceDataset(image_paths_df, per_half_transform=infer_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e5f6660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:14.743734Z",
     "iopub.status.busy": "2025-11-02T02:35:14.743538Z",
     "iopub.status.idle": "2025-11-02T02:35:20.831289Z",
     "shell.execute_reply": "2025-11-02T02:35:20.830406Z"
    },
    "papermill": {
     "duration": 6.092268,
     "end_time": "2025-11-02T02:35:20.832691",
     "exception": false,
     "start_time": "2025-11-02T02:35:14.740423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Infer ========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results_dict = {}\n",
    "\n",
    "for fold in range(3):\n",
    "    best_ckpt = f\"/kaggle/input/csiro-naive-cnn-training/lightning_logs/version_{fold}/checkpoints/best_model_fold{fold}.ckpt\"\n",
    "    model = MultiRegressionModel.load_from_checkpoint(\n",
    "        best_ckpt,\n",
    "        model_name=\"efficientnet_b2\",\n",
    "        pretrained=False,\n",
    "        lr=1e-4,\n",
    "        output_dim=3,\n",
    "        hidden_dim=1536,\n",
    "        open_last_n_blocks=1,\n",
    "        train_bn=False,\n",
    "        map_location=device,\n",
    "    )\n",
    "    model.eval().to(device)\n",
    "\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        use_amp = (device.type == \"cuda\")\n",
    "        amp_dtype = torch.float16\n",
    "        for images in dataloader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            with torch.autocast(\"cuda\", dtype=amp_dtype, enabled=use_amp):\n",
    "                preds = tta_inference(model, images)\n",
    "            results.append(preds.cpu().numpy())\n",
    "\n",
    "    results_dict[fold] = np.concatenate(results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8fa4ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T02:35:20.839479Z",
     "iopub.status.busy": "2025-11-02T02:35:20.839202Z",
     "iopub.status.idle": "2025-11-02T02:35:20.862358Z",
     "shell.execute_reply": "2025-11-02T02:35:20.861800Z"
    },
    "papermill": {
     "duration": 0.027905,
     "end_time": "2025-11-02T02:35:20.863537",
     "exception": false,
     "start_time": "2025-11-02T02:35:20.835632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Construct Submission ========\n",
    "result_df = pd.DataFrame(np.mean([results_dict[fold] for fold in range(3)], axis=0), columns=[\"Dry_Green_g\", \"GDM_g\", \"Dry_Total_g\"])\n",
    "result_df[\"Dry_Dead_g\"] = (result_df[\"Dry_Total_g\"] - result_df[\"GDM_g\"]).clip(lower=0)\n",
    "result_df[\"Dry_Clover_g\"] = (result_df[\"GDM_g\"] - result_df[\"Dry_Green_g\"]).clip(lower=0)\n",
    "result_df['sample_id'] = image_paths_df['id']\n",
    "result_df = pd.melt(result_df, id_vars='sample_id', value_vars=[\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"], value_name='target')\n",
    "result_df['sample_id'] = result_df['sample_id'] + '__' + result_df['variable']\n",
    "result_df['target'] = result_df['target']\n",
    "result_df[['sample_id', 'target']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "sourceId": 272736244,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.068493,
   "end_time": "2025-11-02T02:35:24.160816",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-02T02:34:49.092323",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
