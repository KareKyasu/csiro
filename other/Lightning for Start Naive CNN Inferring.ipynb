{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74922a2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:26.188914Z",
     "iopub.status.busy": "2025-11-01T00:03:26.188346Z",
     "iopub.status.idle": "2025-11-01T00:03:45.018451Z",
     "shell.execute_reply": "2025-11-01T00:03:45.017841Z"
    },
    "papermill": {
     "duration": 18.834984,
     "end_time": "2025-11-01T00:03:45.019820",
     "exception": false,
     "start_time": "2025-11-01T00:03:26.184836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Thanks to tsogtochir.e's public code release (https://www.kaggle.com/code/easterndundrey/csiro-gold-solution), this post was possible.\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f8601e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.025853Z",
     "iopub.status.busy": "2025-11-01T00:03:45.025411Z",
     "iopub.status.idle": "2025-11-01T00:03:45.049186Z",
     "shell.execute_reply": "2025-11-01T00:03:45.048617Z"
    },
    "papermill": {
     "duration": 0.027765,
     "end_time": "2025-11-01T00:03:45.050384",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.022619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Load Datafile ========\n",
    "test_df = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\n",
    "test_df[\"id\"] = test_df[\"sample_id\"].str.split(\"__\").str[0]\n",
    "image_paths_df = test_df[[\"id\",\"image_path\"]].drop_duplicates(\"image_path\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7e0ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.055752Z",
     "iopub.status.busy": "2025-11-01T00:03:45.055527Z",
     "iopub.status.idle": "2025-11-01T00:03:45.065586Z",
     "shell.execute_reply": "2025-11-01T00:03:45.065100Z"
    },
    "papermill": {
     "duration": 0.013907,
     "end_time": "2025-11-01T00:03:45.066650",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.052743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Seed ========\n",
    "def seed_everything(seed: int = 114514):\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    # \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f1c364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.071879Z",
     "iopub.status.busy": "2025-11-01T00:03:45.071371Z",
     "iopub.status.idle": "2025-11-01T00:03:45.075719Z",
     "shell.execute_reply": "2025-11-01T00:03:45.075175Z"
    },
    "papermill": {
     "duration": 0.008053,
     "end_time": "2025-11-01T00:03:45.076828",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.068775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Dataset ========\n",
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open('/kaggle/input/csiro-biomass/' + row[\"image_path\"]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048f7df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.081547Z",
     "iopub.status.busy": "2025-11-01T00:03:45.081359Z",
     "iopub.status.idle": "2025-11-01T00:03:45.087035Z",
     "shell.execute_reply": "2025-11-01T00:03:45.086439Z"
    },
    "papermill": {
     "duration": 0.009198,
     "end_time": "2025-11-01T00:03:45.088047",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.078849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Loss Funtion ========\n",
    "class WeightedR2Loss(nn.Module):\n",
    "    def __init__(self, weights=None, eps=1e-8):\n",
    "        super().__init__()\n",
    "        if weights is None:\n",
    "            weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5])\n",
    "        self.register_buffer('weights', weights)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        y_pred: (B, 3)\n",
    "        y_true: (B, 5)\n",
    "        \"\"\"\n",
    "        DG = y_pred[:,0]\n",
    "        GDM = y_pred[:,1]\n",
    "        DT = y_pred[:,2]\n",
    "        DD = DT - GDM\n",
    "        DC = GDM - DG\n",
    "        y_hat = torch.stack([DG, DD, DC, GDM, DT], dim=1)\n",
    "        \n",
    "        y_mean = torch.mean(y_true, dim=0, keepdim=True)\n",
    "        ss_res = torch.sum((y_true - y_hat) ** 2, dim=0)\n",
    "        ss_tot = torch.sum((y_true - y_mean) ** 2, dim=0)\n",
    "        r2 = 1 - ss_res / (ss_tot + self.eps)\n",
    "\n",
    "        weighted_r2 = torch.sum(self.weights * r2)\n",
    "        loss = 1 - weighted_r2\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10e0bc00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.093182Z",
     "iopub.status.busy": "2025-11-01T00:03:45.092985Z",
     "iopub.status.idle": "2025-11-01T00:03:45.102538Z",
     "shell.execute_reply": "2025-11-01T00:03:45.102030Z"
    },
    "papermill": {
     "duration": 0.013402,
     "end_time": "2025-11-01T00:03:45.103570",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.090168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Model ========\n",
    "class MultiRegressionModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name=\"efficientnet_b2\",\n",
    "        pretrained=False,\n",
    "        lr=1e-4,\n",
    "        output_dim=3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=output_dim, \n",
    "            global_pool=\"avg\"\n",
    "        )\n",
    "\n",
    "        self.criterion = WeightedR2Loss()\n",
    "        self.val_outputs = []\n",
    "\n",
    "    def forward(self, x_img):\n",
    "        return self.backbone(x_img)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_img, y = batch\n",
    "        y_hat = self(x_img)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_img, y = batch\n",
    "        y_hat = self(x_img)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.val_outputs.append((y_hat.detach().cpu(), y.detach().cpu()))\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        y_hats = torch.cat([x[0] for x in self.val_outputs], dim=0)\n",
    "        y_trues = torch.cat([x[1] for x in self.val_outputs], dim=0)\n",
    "        self.val_outputs.clear()\n",
    "\n",
    "        DG = y_hats[:, 0]\n",
    "        GDM = y_hats[:, 1]\n",
    "        DT = y_hats[:, 2]\n",
    "        DD = DT - GDM\n",
    "        DC = GDM - DG\n",
    "        y_hat_full = torch.stack([DG, DD, DC, GDM, DT], dim=1)\n",
    "\n",
    "        y_mean = torch.mean(y_trues, dim=0, keepdim=True)\n",
    "        ss_res = torch.sum((y_trues - y_hat_full) ** 2, dim=0)\n",
    "        ss_tot = torch.sum((y_trues - y_mean) ** 2, dim=0)\n",
    "        r2 = 1 - ss_res / (ss_tot + 1e-8)\n",
    "\n",
    "        weights = self.criterion.weights.cpu()\n",
    "        weighted_r2 = torch.sum(weights * r2)\n",
    "\n",
    "        for i, name in enumerate([\"DG\", \"DD\", \"DC\", \"GDM\", \"DT\"]):\n",
    "            self.log(f\"val_r2_{name}\", r2[i], prog_bar=True, on_epoch=True)\n",
    "        self.log(\"val_weighted_r2\", weighted_r2, prog_bar=True, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode=\"min\",\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            threshold=0.001,\n",
    "            min_lr=1e-7,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b12e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.108359Z",
     "iopub.status.busy": "2025-11-01T00:03:45.108166Z",
     "iopub.status.idle": "2025-11-01T00:03:45.112052Z",
     "shell.execute_reply": "2025-11-01T00:03:45.111505Z"
    },
    "papermill": {
     "duration": 0.007324,
     "end_time": "2025-11-01T00:03:45.113045",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.105721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======== Helpers ========\n",
    "def tta_inference(model, images):\n",
    "    preds = model(images)\n",
    "    preds_lr = model(torch.flip(images, dims=[3]))\n",
    "    preds_ud = model(torch.flip(images, dims=[2]))\n",
    "    preds_lrud = model(torch.flip(images, dims=[2, 3]))\n",
    "    preds_mean = (preds + preds_lr + preds_ud + preds_lrud) / 4.0\n",
    "    return preds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5cd5f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.117879Z",
     "iopub.status.busy": "2025-11-01T00:03:45.117350Z",
     "iopub.status.idle": "2025-11-01T00:03:45.121372Z",
     "shell.execute_reply": "2025-11-01T00:03:45.120863Z"
    },
    "papermill": {
     "duration": 0.007378,
     "end_time": "2025-11-01T00:03:45.122374",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.114996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform\n",
    "img_size = 1000\n",
    "infer_transform = T.Compose([\n",
    "    T.Resize((img_size, img_size)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406],\n",
    "                [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# DataLoader\n",
    "dataset = InferenceDataset(image_paths_df, transform=infer_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7cf6f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:45.127141Z",
     "iopub.status.busy": "2025-11-01T00:03:45.126779Z",
     "iopub.status.idle": "2025-11-01T00:03:52.459511Z",
     "shell.execute_reply": "2025-11-01T00:03:52.458455Z"
    },
    "papermill": {
     "duration": 7.336774,
     "end_time": "2025-11-01T00:03:52.461130",
     "exception": false,
     "start_time": "2025-11-01T00:03:45.124356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "results_dict = {}\n",
    "for fold in range(5):\n",
    "    model = MultiRegressionModel(model_name=\"efficientnet_b2\", pretrained=False)\n",
    "    model.load_state_dict(torch.load(f\"/kaggle/input/csiro-naive-cnn-training/model_fold{fold}.pth\"))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch\n",
    "            images = images.to(device)\n",
    "            preds = tta_inference(model, images)\n",
    "            preds = preds.cpu().numpy()\n",
    "            results.append(preds)\n",
    "    results_dict[fold] = np.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "348c33d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-01T00:03:52.467268Z",
     "iopub.status.busy": "2025-11-01T00:03:52.466447Z",
     "iopub.status.idle": "2025-11-01T00:03:52.489219Z",
     "shell.execute_reply": "2025-11-01T00:03:52.488691Z"
    },
    "papermill": {
     "duration": 0.026725,
     "end_time": "2025-11-01T00:03:52.490289",
     "exception": false,
     "start_time": "2025-11-01T00:03:52.463564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(np.mean([results_dict[fold] for fold in range(5)], axis=0), columns=[\"Dry_Green_g\", \"GDM_g\", \"Dry_Total_g\"])\n",
    "result_df[\"Dry_Dead_g\"] = (result_df[\"Dry_Total_g\"] - result_df[\"GDM_g\"]).clip(lower=0)\n",
    "result_df[\"Dry_Clover_g\"] = (result_df[\"GDM_g\"] - result_df[\"Dry_Green_g\"]).clip(lower=0)\n",
    "result_df['sample_id'] = image_paths_df['id']\n",
    "result_df = pd.melt(result_df, id_vars='sample_id', value_vars=[\"Dry_Green_g\", \"Dry_Dead_g\", \"Dry_Clover_g\", \"GDM_g\", \"Dry_Total_g\"], value_name='target')\n",
    "result_df['sample_id'] = result_df['sample_id'] + '__' + result_df['variable']\n",
    "result_df['target'] = result_df['target'].clip(0, 200)\n",
    "result_df[['sample_id', 'target']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "sourceId": 272500145,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.913411,
   "end_time": "2025-11-01T00:03:55.563581",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-01T00:03:22.650170",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
