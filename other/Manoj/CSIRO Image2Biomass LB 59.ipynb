{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8f192",
   "metadata": {
    "papermill": {
     "duration": 0.004935,
     "end_time": "2025-11-02T12:20:00.901886",
     "exception": false,
     "start_time": "2025-11-02T12:20:00.896951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Here is model training   - https://www.kaggle.com/code/mks2192/csiro-notebook-training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61856a15",
   "metadata": {
    "papermill": {
     "duration": 0.003607,
     "end_time": "2025-11-02T12:20:00.909556",
     "exception": false,
     "start_time": "2025-11-02T12:20:00.905949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Here is Model weights - https://www.kaggle.com/datasets/mks2192/csiro-trained-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0241f",
   "metadata": {
    "papermill": {
     "duration": 0.003824,
     "end_time": "2025-11-02T12:20:00.917150",
     "exception": false,
     "start_time": "2025-11-02T12:20:00.913326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Reference - https://www.kaggle.com/code/none00000/lb-0-57-infer-model-code   https://www.kaggle.com/code/carsoncheng/dinov2-lasso-baseline-lb-0-54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e44c07",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-02T12:20:00.925906Z",
     "iopub.status.busy": "2025-11-02T12:20:00.925637Z",
     "iopub.status.idle": "2025-11-02T12:20:57.431858Z",
     "shell.execute_reply": "2025-11-02T12:20:57.430838Z"
    },
    "papermill": {
     "duration": 56.512311,
     "end_time": "2025-11-02T12:20:57.433232",
     "exception": false,
     "start_time": "2025-11-02T12:20:00.920921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on cuda\n",
      "Models from: /kaggle/input/csiro-trained-model\n",
      "Loaded fold 0\n",
      "Loaded fold 1\n",
      "Loaded fold 2\n",
      "Loaded fold 3\n",
      "Loaded fold 4\n",
      "Running inference on 1 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved: /kaggle/working/submission.csv\n",
      "         image_path  Dry_Green_g  Dry_Dead_g  Dry_Clover_g      GDM_g  \\\n",
      "0  ID1001187975.jpg    26.082348   27.309501      0.975721  27.036599   \n",
      "\n",
      "   Dry_Total_g  \n",
      "0      54.3461  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# CSIRO Image2Biomass â€“ INFERENCE (5-Fold + 4Ã— TTA) â€“ FINAL\n",
    "# MODEL_DIR = /kaggle/input/notebook2c4874f566\n",
    "# ===============================================================\n",
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1. CONFIG\n",
    "# ---------------------------------------------------------------\n",
    "class CFG:\n",
    "    TEST_IMAGE_DIR = '/kaggle/input/csiro-biomass/test'\n",
    "    MODEL_DIR      = '/kaggle/input/csiro-trained-model'\n",
    "    SUBMISSION_DIR = '/kaggle/working/'\n",
    "\n",
    "    MODEL_NAME = 'convnext_tiny'\n",
    "    IMG_SIZE   = 512\n",
    "    N_FOLDS    = 5\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 2\n",
    "    TTA_STEPS  = 4\n",
    "\n",
    "    ALL_TARGET_COLS = ['Dry_Green_g','Dry_Dead_g','Dry_Clover_g','GDM_g','Dry_Total_g']\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Inference on {CFG.DEVICE}\")\n",
    "print(f\"Models from: {CFG.MODEL_DIR}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2. TTA TRANSFORMS â€“ FIXED\n",
    "# ---------------------------------------------------------------\n",
    "def get_tta_transforms():\n",
    "    normalize = A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    to_tensor = ToTensorV2()\n",
    "\n",
    "    return [\n",
    "        A.Compose([A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE), normalize, to_tensor]),\n",
    "        A.Compose([A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE), A.HorizontalFlip(p=1.0), normalize, to_tensor]),\n",
    "        A.Compose([A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE), A.VerticalFlip(p=1.0),   normalize, to_tensor]),\n",
    "        A.Compose([A.Resize(CFG.IMG_SIZE, CFG.IMG_SIZE), A.HorizontalFlip(p=1.0), A.VerticalFlip(p=1.0), normalize, to_tensor]),\n",
    "    ]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. TEST DATASET\n",
    "# ---------------------------------------------------------------\n",
    "class BiomassTestDataset(Dataset):\n",
    "    def __init__(self, img_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.paths = sorted([\n",
    "            os.path.join(img_dir, f) for f in os.listdir(img_dir)\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ])\n",
    "        self.filenames = [os.path.basename(p) for p in self.paths]\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            img = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        mid = w // 2\n",
    "        left  = img[:, :mid].copy()\n",
    "        right = img[:, mid:].copy()\n",
    "\n",
    "        return left, right, self.filenames[idx]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4. MODEL\n",
    "# ---------------------------------------------------------------\n",
    "class BiomassModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, global_pool='avg')\n",
    "        nf = self.backbone.num_features\n",
    "        comb = nf * 2\n",
    "        head = lambda: nn.Sequential(nn.Linear(comb, comb//2), nn.ReLU(inplace=True),\n",
    "                                     nn.Dropout(0.3), nn.Linear(comb//2, 1))\n",
    "        self.head_total = head(); self.head_gdm = head(); self.head_green = head()\n",
    "\n",
    "    def forward(self, left, right):\n",
    "        fl = self.backbone(left)\n",
    "        fr = self.backbone(right)\n",
    "        x = torch.cat([fl, fr], dim=1)\n",
    "        return self.head_total(x), self.head_gdm(x), self.head_green(x)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. TTA PREDICTION\n",
    "# ---------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def predict_tta(model, left_np, right_np, tta_tfms):\n",
    "    preds = []\n",
    "    for tfm in tta_tfms:\n",
    "        l = tfm(image=left_np)['image'].unsqueeze(0).to(CFG.DEVICE)\n",
    "        r = tfm(image=right_np)['image'].unsqueeze(0).to(CFG.DEVICE)\n",
    "        p_tot, p_gdm, p_green = model(l, r)\n",
    "        p_tot, p_gdm, p_green = p_tot.item(), p_gdm.item(), p_green.item()\n",
    "        p_clover = max(p_gdm - p_green, 0)\n",
    "        p_dead   = max(p_tot - p_gdm, 0)\n",
    "        preds.append([p_green, p_dead, p_clover, p_gdm, p_tot])\n",
    "    return np.mean(preds, axis=0)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 6. MAIN INFERENCE\n",
    "# ---------------------------------------------------------------\n",
    "def run_inference():\n",
    "    models = []\n",
    "    for fold in range(CFG.N_FOLDS):\n",
    "        path = os.path.join(CFG.MODEL_DIR, f'best_model_fold{fold}.pth')\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(path)\n",
    "        m = BiomassModel(CFG.MODEL_NAME)\n",
    "        m.load_state_dict(torch.load(path, map_location=CFG.DEVICE))\n",
    "        m.eval().to(CFG.DEVICE)\n",
    "        models.append(m)\n",
    "        print(f\"Loaded fold {fold}\")\n",
    "\n",
    "    tta_tfms = get_tta_transforms()\n",
    "    dataset = BiomassTestDataset(CFG.TEST_IMAGE_DIR)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=CFG.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        collate_fn=lambda x: x\n",
    "    )\n",
    "\n",
    "    all_preds = []\n",
    "    all_names = []\n",
    "\n",
    "    print(f\"Running inference on {len(dataset)} images...\")\n",
    "    for batch in tqdm(loader, desc=\"Inference\"):\n",
    "        for left_np, right_np, name in batch:\n",
    "            fold_preds = [predict_tta(m, left_np, right_np, tta_tfms) for m in models]\n",
    "            final_pred = np.mean(fold_preds, axis=0)\n",
    "            all_preds.append(final_pred)\n",
    "            all_names.append(name)\n",
    "\n",
    "    sub = pd.DataFrame(all_preds, columns=CFG.ALL_TARGET_COLS)\n",
    "    sub.insert(0, 'image_path', all_names)\n",
    "    sub = sub.sort_values('image_path').reset_index(drop=True)\n",
    "    out_path = os.path.join(CFG.SUBMISSION_DIR, 'submission.csv')\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(f\"\\nSubmission saved: {out_path}\")\n",
    "    print(sub.head())\n",
    "    return sub\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 7. RUN\n",
    "# ---------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    submission = run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b69d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:20:57.443688Z",
     "iopub.status.busy": "2025-11-02T12:20:57.443214Z",
     "iopub.status.idle": "2025-11-02T12:20:57.472193Z",
     "shell.execute_reply": "2025-11-02T12:20:57.471493Z"
    },
    "papermill": {
     "duration": 0.035294,
     "end_time": "2025-11-02T12:20:57.473319",
     "exception": false,
     "start_time": "2025-11-02T12:20:57.438025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading your predictions...\n",
      "Loaded 1 rows\n",
      "         image_path  Dry_Green_g  Dry_Dead_g  Dry_Clover_g      GDM_g  \\\n",
      "0  ID1001187975.jpg    26.082348   27.309501      0.975721  27.036599   \n",
      "\n",
      "   Dry_Total_g  \n",
      "0      54.3461  \n",
      "\n",
      "Competition submission saved â†’ /kaggle/working/submission1.csv\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.975721\n",
      "1    ID1001187975__Dry_Dead_g  27.309501\n",
      "2   ID1001187975__Dry_Green_g  26.082348\n",
      "3   ID1001187975__Dry_Total_g  54.346100\n",
      "4         ID1001187975__GDM_g  27.036599\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------------\n",
    "INPUT_SUBMISSION  = '/kaggle/working/submission.csv'   # <-- your current file\n",
    "TEST_CSV          = '/kaggle/input/csiro-biomass/test.csv'\n",
    "OUTPUT_SUBMISSION = '/kaggle/working/submission1.csv'\n",
    "\n",
    "# Target column names (must match exactly)\n",
    "TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1. Load your predictions (wide format)\n",
    "# ---------------------------------------------------------------\n",
    "print(\"Loading your predictions...\")\n",
    "df_wide = pd.read_csv(INPUT_SUBMISSION)\n",
    "print(f\"Loaded {len(df_wide)} rows\")\n",
    "print(df_wide.head())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2. Extract image name without .jpg\n",
    "# ---------------------------------------------------------------\n",
    "df_wide['image_path'] = df_wide['image_path'].astype(str)\n",
    "df_wide['image_name'] = df_wide['image_path'].str.replace('.jpg', '', regex=False)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. Melt to long format\n",
    "# ---------------------------------------------------------------\n",
    "df_long = df_wide.melt(\n",
    "    id_vars='image_name',\n",
    "    value_vars=TARGET_COLS,\n",
    "    var_name='target_name',\n",
    "    value_name='target'\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4. Create sample_id = image_name + __ + target_name\n",
    "# ---------------------------------------------------------------\n",
    "df_long['sample_id'] = df_long['image_name'] + '__' + df_long['target_name']\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. Final DataFrame\n",
    "# ---------------------------------------------------------------\n",
    "submission = df_long[['sample_id', 'target']].copy()\n",
    "submission = submission.sort_values('sample_id').reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 6. Save\n",
    "# ---------------------------------------------------------------\n",
    "submission.to_csv(OUTPUT_SUBMISSION, index=False)\n",
    "print(f\"\\nCompetition submission saved â†’ {OUTPUT_SUBMISSION}\")\n",
    "print(submission.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2f89e",
   "metadata": {
    "papermill": {
     "duration": 0.004366,
     "end_time": "2025-11-02T12:20:57.482417",
     "exception": false,
     "start_time": "2025-11-02T12:20:57.478051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2f44bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:20:57.492276Z",
     "iopub.status.busy": "2025-11-02T12:20:57.492007Z",
     "iopub.status.idle": "2025-11-02T12:21:06.661037Z",
     "shell.execute_reply": "2025-11-02T12:21:06.660078Z"
    },
    "papermill": {
     "duration": 9.175479,
     "end_time": "2025-11-02T12:21:06.662187",
     "exception": false,
     "start_time": "2025-11-02T12:20:57.486708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sá»­ dá»¥ng thiáº¿t bá»‹: cuda\n",
      "Backbone mÃ´ hÃ¬nh: convnext_tiny\n",
      "KÃ­ch thÆ°á»›c áº£nh inference: 768x768\n",
      "ÄÃ£ Ä‘á»‹nh nghÄ©a hÃ m get_tta_transforms().\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Báº®T Äáº¦U INFERENCE (vá»›i TTA) ðŸš€\n",
      "==================================================\n",
      "Äang táº£i /kaggle/input/csiro-biomass/test.csv...\n",
      "TÃ¬m tháº¥y 1 áº£nh test duy nháº¥t.\n",
      "\n",
      "Äang táº£i 5 mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n...\n",
      "âœ“ ÄÃ£ táº£i thÃ nh cÃ´ng 5 mÃ´ hÃ¬nh.\n",
      "\n",
      "Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n vá»›i 3 TTA views...\n",
      "--- Äang cháº¡y TTA View 1/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HoÃ n thÃ nh TTA View 1\n",
      "--- Äang cháº¡y TTA View 2/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HoÃ n thÃ nh TTA View 2\n",
      "--- Äang cháº¡y TTA View 3/3 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ HoÃ n thÃ nh TTA View 3\n",
      "\n",
      "Äang ensemble káº¿t quáº£ cá»§a cÃ¡c TTA views...\n",
      "âœ“ Dá»± Ä‘oÃ¡n hoÃ n táº¥t.\n",
      "\n",
      "Äang háº­u xá»­ lÃ½ vÃ  táº¡o file submission...\n",
      "\n",
      "ðŸŽ‰ HOÃ€N Táº¤T! ÄÃ£ lÆ°u file submission táº¡i: submission.csv\n",
      "--- 5 hÃ ng Ä‘áº§u cá»§a file submission ---\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.821140\n",
      "1    ID1001187975__Dry_Dead_g  27.369932\n",
      "2   ID1001187975__Dry_Green_g  23.856733\n",
      "3   ID1001187975__Dry_Total_g  52.047806\n",
      "4         ID1001187975__GDM_g  24.677874\n",
      "\n",
      "--- 5 hÃ ng cuá»‘i cá»§a file submission ---\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.821140\n",
      "1    ID1001187975__Dry_Dead_g  27.369932\n",
      "2   ID1001187975__Dry_Green_g  23.856733\n",
      "3   ID1001187975__Dry_Total_g  52.047806\n",
      "4         ID1001187975__GDM_g  24.677874\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# ===============================================================\n",
    "# 1. âš™ï¸ CONFIGURATION (PHáº¢I GIá»NG Há»†T FILE TRAINING)\n",
    "# ===============================================================\n",
    "class CFG:\n",
    "    # --- ÄÆ°á»ng dáº«n (Paths) ---\n",
    "    # (HÃ£y Ä‘iá»u chá»‰nh cÃ¡c Ä‘Æ°á»ng dáº«n nÃ y cho Ä‘Ãºng vá»›i mÃ´i trÆ°á»ng cá»§a báº¡n)\n",
    "    BASE_PATH = '/kaggle/input/csiro-biomass'\n",
    "    TEST_CSV = os.path.join(BASE_PATH, 'test.csv')\n",
    "    TEST_IMAGE_DIR = os.path.join(BASE_PATH, 'test')\n",
    "    \n",
    "    # ThÆ° má»¥c chá»©a 5 file .pth\n",
    "    MODEL_DIR = '/kaggle/input/csiro/' # Giáº£ sá»­ 5 file .pth náº±m cÃ¹ng thÆ° má»¥c\n",
    "    SUBMISSION_FILE = 'submission.csv'\n",
    "    \n",
    "    # --- CÃ i Ä‘áº·t MÃ´ hÃ¬nh (PHáº¢I TRÃ™NG KHá»šP) ---\n",
    "    MODEL_NAME = 'convnext_tiny' # PHáº¢I GIá»NG Há»†T LÃšC TRAIN\n",
    "    IMG_SIZE = 768               # PHáº¢I GIá»NG Há»†T LÃšC TRAIN\n",
    "    \n",
    "    # --- CÃ i Ä‘áº·t Inference ---\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    BATCH_SIZE = 1 # CÃ³ thá»ƒ tÄƒng batch size khi inference\n",
    "    NUM_WORKERS = 1\n",
    "    N_FOLDS = 5\n",
    "    \n",
    "    # --- Má»¥c tiÃªu & Loss (PHáº¢I TRÃ™NG KHá»šP) ---\n",
    "    # 3 má»¥c tiÃªu model Ä‘Ã£ dá»± Ä‘oÃ¡n\n",
    "    TARGET_COLS = ['Dry_Total_g', 'GDM_g', 'Dry_Green_g']\n",
    "    \n",
    "    # 5 má»¥c tiÃªu Ä‘á»ƒ ná»™p bÃ i\n",
    "    ALL_TARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "print(f\"Sá»­ dá»¥ng thiáº¿t bá»‹: {CFG.DEVICE}\")\n",
    "print(f\"Backbone mÃ´ hÃ¬nh: {CFG.MODEL_NAME}\")\n",
    "print(f\"KÃ­ch thÆ°á»›c áº£nh inference: {CFG.IMG_SIZE}x{CFG.IMG_SIZE}\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 2. ðŸžï¸ AUGMENTATIONS (CHá»ˆ DÃ™NG VALIDATION)\n",
    "# ===============================================================\n",
    "from albumentations import (\n",
    "    Compose, \n",
    "    Resize, \n",
    "    Normalize,\n",
    "    HorizontalFlip, \n",
    "    VerticalFlip\n",
    ")\n",
    "\n",
    "def get_tta_transforms():\n",
    "    \"\"\"\n",
    "    Tráº£ vá» má»™t LIST cÃ¡c pipeline transform cho TTA.\n",
    "    Má»—i pipeline lÃ  má»™t \"view\" khÃ¡c nhau cá»§a áº£nh.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ÄÃ¢y lÃ  cÃ¡c bÆ°á»›c chuáº©n hÃ³a cÆ¡ báº£n\n",
    "    base_transforms = [\n",
    "        Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    "    \n",
    "    # -----------------\n",
    "    # View 1: áº¢nh gá»‘c (Chá»‰ Resize + Normalize)\n",
    "    # -----------------\n",
    "    original_view = Compose([\n",
    "        Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n",
    "        *base_transforms\n",
    "    ])\n",
    "    \n",
    "    # -----------------\n",
    "    # View 2: Láº­t ngang (HFlip)\n",
    "    # -----------------\n",
    "    hflip_view = Compose([\n",
    "        HorizontalFlip(p=1.0), # LuÃ´n luÃ´n láº­t\n",
    "        Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n",
    "        *base_transforms\n",
    "    ])\n",
    "    \n",
    "    # -----------------\n",
    "    # View 3: Láº­t dá»c (VFlip)\n",
    "    # -----------------\n",
    "    vflip_view = Compose([\n",
    "        VerticalFlip(p=1.0), # LuÃ´n luÃ´n láº­t\n",
    "        Resize(CFG.IMG_SIZE, CFG.IMG_SIZE),\n",
    "        *base_transforms\n",
    "    ])\n",
    "    \n",
    "    return [original_view, hflip_view, vflip_view]\n",
    "\n",
    "print(\"ÄÃ£ Ä‘á»‹nh nghÄ©a hÃ m get_tta_transforms().\")\n",
    "\n",
    "\n",
    "class TestBiomassDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset tÃ¹y chá»‰nh cho áº£nh test (Chiáº¿n lÆ°á»£c \"Hai luá»“ng\").\n",
    "    Sá»­a Ä‘á»•i Ä‘á»ƒ cháº¥p nháº­n má»™t pipeline transform cá»¥ thá»ƒ cho TTA.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform_pipeline, image_dir):\n",
    "        self.df = df\n",
    "        # (Sá»¬A Äá»”I) Cháº¥p nháº­n má»™t pipeline Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o\n",
    "        self.transforms = transform_pipeline \n",
    "        self.image_dir = image_dir\n",
    "        self.image_paths = df['image_path'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Láº¥y thÃ´ng tin\n",
    "        img_path_suffix = self.image_paths[idx]\n",
    "        \n",
    "        # 2. Äá»c áº£nh gá»‘c (2000x1000)\n",
    "        filename = os.path.basename(img_path_suffix)\n",
    "        full_path = os.path.join(self.image_dir, filename)\n",
    "        \n",
    "        image = cv2.imread(full_path)\n",
    "        if image is None:\n",
    "            print(f\"Warning: KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {full_path}. Tráº£ vá» áº£nh Ä‘en.\")\n",
    "            image = np.zeros((1000, 2000, 3), dtype=np.uint8)\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 3. Cáº¯t (Crop) thÃ nh 2 áº£nh (TrÃ¡i vÃ  Pháº£i)\n",
    "        height, width, _ = image.shape\n",
    "        mid_point = width // 2\n",
    "        img_left = image[:, :mid_point]\n",
    "        img_right = image[:, mid_point:]\n",
    "        \n",
    "        # 4. Ãp dá»¥ng TTA Transform (CÃ™NG Má»˜T TRANSFORM cho cáº£ 2)\n",
    "        # (VÃ­ dá»¥: Cáº£ 2 áº£nh Ä‘á»u bá»‹ láº­t ngang)\n",
    "        img_left_tensor = self.transforms(image=img_left)['image']\n",
    "        img_right_tensor = self.transforms(image=img_right)['image']\n",
    "        \n",
    "        # 5. Tráº£ vá»\n",
    "        return img_left_tensor, img_right_tensor\n",
    "\n",
    "# ===============================================================\n",
    "# 4. ðŸ§  MODEL ARCHITECTURE (SAO CHÃ‰P Tá»ª FILE TRAIN)\n",
    "# ===============================================================\n",
    "class BiomassModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Kiáº¿n trÃºc mÃ´ hÃ¬nh (Hai luá»“ng, Ba Ä‘áº§u ra)\n",
    "    PHáº¢I GIá»NG Há»†T file training.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, pretrained, n_targets=3):\n",
    "        super(BiomassModel, self).__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained, # Sáº½ lÃ  False khi inference\n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        self.n_features = self.backbone.num_features\n",
    "        self.n_combined_features = self.n_features * 2\n",
    "        \n",
    "        # --- Äáº§u cho Dry_Total_g ---\n",
    "        self.head_total = nn.Sequential(\n",
    "            nn.Linear(self.n_combined_features, self.n_combined_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.n_combined_features // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # --- Äáº§u cho GDM_g ---\n",
    "        self.head_gdm = nn.Sequential(\n",
    "            nn.Linear(self.n_combined_features, self.n_combined_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.n_combined_features // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # --- Äáº§u cho Dry_Green_g ---\n",
    "        self.head_green = nn.Sequential(\n",
    "            nn.Linear(self.n_combined_features, self.n_combined_features // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.n_combined_features // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img_left, img_right):\n",
    "        features_left = self.backbone(img_left)\n",
    "        features_right = self.backbone(img_right)\n",
    "        combined = torch.cat([features_left, features_right], dim=1)\n",
    "        \n",
    "        out_total = self.head_total(combined)\n",
    "        out_gdm = self.head_gdm(combined)\n",
    "        out_green = self.head_green(combined)\n",
    "        \n",
    "        return out_total, out_gdm, out_green\n",
    "\n",
    "\n",
    "def predict_one_view(models_list, test_loader, device):\n",
    "    \"\"\"\n",
    "    HÃ m con: Cháº¡y dá»± Ä‘oÃ¡n ensemble 5-fold cho Má»˜T view TTA.\n",
    "    \"\"\"\n",
    "    view_preds_3 = {'total': [], 'gdm': [], 'green': []}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (img_left, img_right) in tqdm(test_loader, desc=\"  Predicting View\", leave=False):\n",
    "            img_left = img_left.to(device)\n",
    "            img_right = img_right.to(device)\n",
    "            \n",
    "            batch_preds_3_folds = {'total': [], 'gdm': [], 'green': []}\n",
    "            \n",
    "            # 1. VÃ²ng láº·p Ensemble 5-Fold\n",
    "            for model in models_list:\n",
    "                pred_total, pred_gdm, pred_green = model(img_left, img_right)\n",
    "                batch_preds_3_folds['total'].append(pred_total.cpu())\n",
    "                batch_preds_3_folds['gdm'].append(pred_gdm.cpu())\n",
    "                batch_preds_3_folds['green'].append(pred_green.cpu())\n",
    "            \n",
    "            # 2. Láº¥y trung bÃ¬nh 5 Fold\n",
    "            avg_pred_total = torch.mean(torch.stack(batch_preds_3_folds['total']), dim=0)\n",
    "            avg_pred_gdm = torch.mean(torch.stack(batch_preds_3_folds['gdm']), dim=0)\n",
    "            avg_pred_green = torch.mean(torch.stack(batch_preds_3_folds['green']), dim=0)\n",
    "            \n",
    "            view_preds_3['total'].append(avg_pred_total.numpy())\n",
    "            view_preds_3['gdm'].append(avg_pred_gdm.numpy())\n",
    "            view_preds_3['green'].append(avg_pred_green.numpy())\n",
    "\n",
    "    # 3. GhÃ©p káº¿t quáº£ cÃ¡c batch cá»§a view nÃ y\n",
    "    preds_np = {\n",
    "        'total': np.concatenate(view_preds_3['total']).flatten(),\n",
    "        'gdm':   np.concatenate(view_preds_3['gdm']).flatten(),\n",
    "        'green': np.concatenate(view_preds_3['green']).flatten()\n",
    "    }\n",
    "    return preds_np\n",
    "\n",
    "\n",
    "def run_inference_with_tta():\n",
    "    \"\"\"\n",
    "    HÃ m inference chÃ­nh, thá»±c hiá»‡n TTA x Ensemble.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ðŸš€ Báº®T Äáº¦U INFERENCE (vá»›i TTA) ðŸš€\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # --- 1. Táº£i Dá»¯ liá»‡u Test ---\n",
    "    print(f\"Äang táº£i {CFG.TEST_CSV}...\")\n",
    "    try:\n",
    "        test_df_long = pd.read_csv(CFG.TEST_CSV)\n",
    "        test_df_unique = test_df_long.drop_duplicates(subset=['image_path']).reset_index(drop=True)\n",
    "        print(f\"TÃ¬m tháº¥y {len(test_df_unique)} áº£nh test duy nháº¥t.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lá»–I: KhÃ´ng tÃ¬m tháº¥y {CFG.TEST_CSV}\")\n",
    "        return None, None, None\n",
    "\n",
    "    # --- 2. Táº£i 5 MÃ´ hÃ¬nh (Ensemble) ---\n",
    "    print(\"\\nÄang táº£i 5 mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n...\")\n",
    "    models_list = []\n",
    "    # (Code táº£i 5 mÃ´ hÃ¬nh... giá»‘ng há»‡t bÆ°á»›c 16 cá»§a file trÆ°á»›c)\n",
    "    for fold in range(CFG.N_FOLDS):\n",
    "        model_path = os.path.join(CFG.MODEL_DIR, f'best_model_fold{fold}.pth')\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"Lá»–I: KhÃ´ng tÃ¬m tháº¥y file mÃ´ hÃ¬nh: {model_path}\")\n",
    "            return None, None, None\n",
    "        model = BiomassModel(CFG.MODEL_NAME, pretrained=False)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(model_path, map_location=CFG.DEVICE))\n",
    "        except RuntimeError:\n",
    "            state_dict = torch.load(model_path, map_location=CFG.DEVICE)\n",
    "            from collections import OrderedDict\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in state_dict.items():\n",
    "                name = k.replace('module.', '')\n",
    "                new_state_dict[name] = v\n",
    "            model.load_state_dict(new_state_dict)\n",
    "        model.eval()\n",
    "        model.to(CFG.DEVICE)\n",
    "        models_list.append(model)\n",
    "    print(f\"âœ“ ÄÃ£ táº£i thÃ nh cÃ´ng {len(models_list)} mÃ´ hÃ¬nh.\")\n",
    "\n",
    "    # --- 3. VÃ²ng láº·p TTA (VÃ²ng láº·p ngoÃ i) ---\n",
    "    tta_transforms = get_tta_transforms()\n",
    "    print(f\"\\nBáº¯t Ä‘áº§u dá»± Ä‘oÃ¡n vá»›i {len(tta_transforms)} TTA views...\")\n",
    "    \n",
    "    all_tta_view_preds = [] # List Ä‘á»ƒ lÆ°u káº¿t quáº£ cá»§a má»—i view TTA\n",
    "\n",
    "    for i, tta_transform in enumerate(tta_transforms):\n",
    "        print(f\"--- Äang cháº¡y TTA View {i+1}/{len(tta_transforms)} ---\")\n",
    "        \n",
    "        # Táº¡o Dataset/Loader Má»šI cho view TTA nÃ y\n",
    "        test_dataset = TestBiomassDataset(\n",
    "            df=test_df_unique,\n",
    "            transform_pipeline=tta_transform, # Truyá»n pipeline TTA\n",
    "            image_dir=CFG.TEST_IMAGE_DIR\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CFG.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=CFG.NUM_WORKERS,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Cháº¡y ensemble 5-fold cho view nÃ y\n",
    "        view_preds_np = predict_one_view(models_list, test_loader, CFG.DEVICE)\n",
    "        all_tta_view_preds.append(view_preds_np)\n",
    "        print(f\"âœ“ HoÃ n thÃ nh TTA View {i+1}\")\n",
    "\n",
    "    # --- 4. Ensemble (Láº¥y trung bÃ¬nh) káº¿t quáº£ TTA ---\n",
    "    print(\"\\nÄang ensemble káº¿t quáº£ cá»§a cÃ¡c TTA views...\")\n",
    "    final_ensembled_preds = {\n",
    "        'total': np.mean([d['total'] for d in all_tta_view_preds], axis=0),\n",
    "        'gdm':   np.mean([d['gdm'] for d in all_tta_view_preds], axis=0),\n",
    "        'green': np.mean([d['green'] for d in all_tta_view_preds], axis=0)\n",
    "    }\n",
    "    \n",
    "    print(\"âœ“ Dá»± Ä‘oÃ¡n hoÃ n táº¥t.\")\n",
    "    \n",
    "    del models_list, test_loader, test_dataset\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return final_ensembled_preds, test_df_long, test_df_unique\n",
    "# ===============================================================\n",
    "# 6. âœï¸ HÃ€M Táº O FILE SUBMISSION\n",
    "# ===============================================================\n",
    "def create_submission(preds_np, test_df_long, test_df_unique):\n",
    "    \"\"\"\n",
    "    HÃ m nÃ y nháº­n 3 dá»± Ä‘oÃ¡n Ä‘Ã£ ensemble,\n",
    "    tÃ­nh toÃ¡n 2 dá»± Ä‘oÃ¡n cÃ²n láº¡i,\n",
    "    vÃ  Ä‘á»‹nh dáº¡ng file ná»™p bÃ i.\n",
    "    \"\"\"\n",
    "    if preds_np is None:\n",
    "        print(\"Bá» qua táº¡o submission do lá»—i á»Ÿ trÃªn.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nÄang háº­u xá»­ lÃ½ vÃ  táº¡o file submission...\")\n",
    "\n",
    "    # 1. Láº¥y 3 dá»± Ä‘oÃ¡n Ä‘Ã£ ensemble\n",
    "    pred_total_final = preds_np['total']\n",
    "    pred_gdm_final = preds_np['gdm']\n",
    "    pred_green_final = preds_np['green']\n",
    "\n",
    "    # 2. TÃ­nh 2 má»¥c tiÃªu cÃ²n láº¡i (Háº­u xá»­ lÃ½)\n",
    "    # DÃ¹ng np.maximum(0, ...) Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ giÃ¡ trá»‹ Ã¢m\n",
    "    pred_clover_final = np.maximum(0, pred_gdm_final - pred_green_final)\n",
    "    pred_dead_final = np.maximum(0, pred_total_final - pred_gdm_final)\n",
    "\n",
    "    # 3. Táº¡o má»™t DataFrame \"wide\" chá»©a 5 dá»± Ä‘oÃ¡n\n",
    "    # (Äáº£m báº£o thá»© tá»± 5 cá»™t giá»‘ng CFG.ALL_TARGET_COLS)\n",
    "    preds_wide_df = pd.DataFrame({\n",
    "        'image_path': test_df_unique['image_path'],\n",
    "        'Dry_Green_g': pred_green_final,\n",
    "        'Dry_Dead_g': pred_dead_final,\n",
    "        'Dry_Clover_g': pred_clover_final,\n",
    "        'GDM_g': pred_gdm_final,\n",
    "        'Dry_Total_g': pred_total_final\n",
    "    })\n",
    "\n",
    "    # 4. \"Un-pivot\" DataFrame (Chuyá»ƒn sang dáº¡ng \"long\")\n",
    "    # Biáº¿n nÃ³ tá»« 5 cá»™t vá» dáº¡ng \"long\" (giá»‘ng sample_submission)\n",
    "    preds_long_df = preds_wide_df.melt(\n",
    "        id_vars=['image_path'],\n",
    "        value_vars=CFG.ALL_TARGET_COLS, # 5 cá»™t má»¥c tiÃªu\n",
    "        var_name='target_name',        # Cá»™t tÃªn má»¥c tiÃªu\n",
    "        value_name='target'            # Cá»™t giÃ¡ trá»‹ dá»± Ä‘oÃ¡n\n",
    "    )\n",
    "\n",
    "    # 5. Merge vá»›i file test.csv gá»‘c (test_df_long)\n",
    "    # ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng Ä‘á»ƒ láº¥y Ä‘Ãºng 'sample_id'\n",
    "    # (vÃ­ dá»¥: 'ID1001187975__Dry_Clover_g')\n",
    "    submission_df = pd.merge(\n",
    "        test_df_long[['sample_id', 'image_path', 'target_name']],\n",
    "        preds_long_df,\n",
    "        on=['image_path', 'target_name'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 6. Dá»n dáº¹p vÃ  LÆ°u\n",
    "    # Chá»‰ giá»¯ láº¡i 2 cá»™t Ä‘Æ°á»£c yÃªu cáº§u\n",
    "    submission_df = submission_df[['sample_id', 'target']]\n",
    "    \n",
    "    # LÆ°u file\n",
    "    submission_df.to_csv(CFG.SUBMISSION_FILE, index=False)\n",
    "\n",
    "    print(f\"\\nðŸŽ‰ HOÃ€N Táº¤T! ÄÃ£ lÆ°u file submission táº¡i: {CFG.SUBMISSION_FILE}\")\n",
    "    print(\"--- 5 hÃ ng Ä‘áº§u cá»§a file submission ---\")\n",
    "    print(submission_df.head())\n",
    "    print(\"\\n--- 5 hÃ ng cuá»‘i cá»§a file submission ---\")\n",
    "    print(submission_df.tail())\n",
    "    \n",
    "# ===============================================================\n",
    "# 8. ðŸ CHáº Y CHÆ¯Æ NG TRÃŒNH (ÄÃ£ sá»­a)\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Cháº¡y dá»± Ä‘oÃ¡n (Ä‘Ã£ bao gá»“m TTA)\n",
    "    all_preds_np, df_long, df_unique = run_inference_with_tta()\n",
    "    \n",
    "    # 2. Táº¡o file submission (HÃ m create_submission giá»¯ nguyÃªn)\n",
    "    create_submission(all_preds_np, df_long, df_unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7505e",
   "metadata": {
    "papermill": {
     "duration": 0.004932,
     "end_time": "2025-11-02T12:21:06.672530",
     "exception": false,
     "start_time": "2025-11-02T12:21:06.667598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b1ce6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:21:06.683684Z",
     "iopub.status.busy": "2025-11-02T12:21:06.683424Z",
     "iopub.status.idle": "2025-11-02T12:21:06.828804Z",
     "shell.execute_reply": "2025-11-02T12:21:06.827884Z"
    },
    "papermill": {
     "duration": 0.152275,
     "end_time": "2025-11-02T12:21:06.829988",
     "exception": false,
     "start_time": "2025-11-02T12:21:06.677713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from PIL import Image\n",
    "!cp -r \"/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main\" /kaggle/working/dinov2\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c019f360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:21:06.841355Z",
     "iopub.status.busy": "2025-11-02T12:21:06.841114Z",
     "iopub.status.idle": "2025-11-02T12:21:27.180011Z",
     "shell.execute_reply": "2025-11-02T12:21:27.179364Z"
    },
    "papermill": {
     "duration": 20.346201,
     "end_time": "2025-11-02T12:21:27.181350",
     "exception": false,
     "start_time": "2025-11-02T12:21:06.835149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 12:21:10.237612: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762086070.434479      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762086070.488829      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/')\n",
    "model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb7a191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:21:27.193406Z",
     "iopub.status.busy": "2025-11-02T12:21:27.192924Z",
     "iopub.status.idle": "2025-11-02T12:22:21.284327Z",
     "shell.execute_reply": "2025-11-02T12:22:21.283509Z"
    },
    "papermill": {
     "duration": 54.098866,
     "end_time": "2025-11-02T12:22:21.285844",
     "exception": false,
     "start_time": "2025-11-02T12:21:27.186978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3300202635.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  x = torch.tensor(processor(img).pixel_values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 batches processed.\n",
      "200 batches processed.\n",
      "300 batches processed.\n"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "targets = [[] for i in range(5)]\n",
    "counter = 0\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "#transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std)])\n",
    "train_df = pd.read_csv(\"/kaggle/input/csiro-biomass/train.csv\")\n",
    "root = \"/kaggle/input/csiro-biomass/\"\n",
    "for i in range(len(train_df)):\n",
    "    entry = train_df.iloc[i]\n",
    "    file_path = root + entry['image_path']\n",
    "    y = torch.tensor([[entry['target']]])\n",
    "    targets[i % 5].append(y)\n",
    "    if i % 5 == 0:\n",
    "        img = Image.open(file_path)\n",
    "        x = torch.tensor(processor(img).pixel_values)\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            embeds.append(model(x).pooler_output.cpu())\n",
    "            counter += 1\n",
    "            if counter % 100 == 0:\n",
    "                print(f\"{counter} batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad3c81b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:21.298506Z",
     "iopub.status.busy": "2025-11-02T12:22:21.298175Z",
     "iopub.status.idle": "2025-11-02T12:22:21.767695Z",
     "shell.execute_reply": "2025-11-02T12:22:21.766739Z"
    },
    "papermill": {
     "duration": 0.477319,
     "end_time": "2025-11-02T12:22:21.769106",
     "exception": false,
     "start_time": "2025-11-02T12:22:21.291787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target 1 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.6520\n",
      "  Val RÂ²: 0.4083\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.6006\n",
      "  Val RÂ²: 0.6426\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.6318\n",
      "  Val RÂ²: 0.5823\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.6516\n",
      "  Val RÂ²: 0.4472\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.6311\n",
      "  Val RÂ²: 0.4461\n",
      "\n",
      "Target 1 Average:\n",
      "  Avg Train RÂ²: 0.6334\n",
      "  Avg Val RÂ²: 0.5053\n",
      "\n",
      "=== Target 2 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.4422\n",
      "  Val RÂ²: 0.3771\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.4612\n",
      "  Val RÂ²: 0.1990\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.4716\n",
      "  Val RÂ²: 0.3107\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.4591\n",
      "  Val RÂ²: 0.3874\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.4195\n",
      "  Val RÂ²: 0.4719\n",
      "\n",
      "Target 2 Average:\n",
      "  Avg Train RÂ²: 0.4507\n",
      "  Avg Val RÂ²: 0.3492\n",
      "\n",
      "=== Target 3 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.8262\n",
      "  Val RÂ²: 0.7079\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.8337\n",
      "  Val RÂ²: 0.6208\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.8339\n",
      "  Val RÂ²: 0.6039\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.8342\n",
      "  Val RÂ²: 0.6463\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.8227\n",
      "  Val RÂ²: 0.7007\n",
      "\n",
      "Target 3 Average:\n",
      "  Avg Train RÂ²: 0.8301\n",
      "  Avg Val RÂ²: 0.6559\n",
      "\n",
      "=== Target 4 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.7606\n",
      "  Val RÂ²: 0.5641\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.7942\n",
      "  Val RÂ²: 0.4437\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.7686\n",
      "  Val RÂ²: 0.5105\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.7600\n",
      "  Val RÂ²: 0.5493\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.7635\n",
      "  Val RÂ²: 0.5781\n",
      "\n",
      "Target 4 Average:\n",
      "  Avg Train RÂ²: 0.7693\n",
      "  Avg Val RÂ²: 0.5291\n",
      "\n",
      "=== Target 5 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.8107\n",
      "  Val RÂ²: 0.6607\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.8266\n",
      "  Val RÂ²: 0.6512\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.8256\n",
      "  Val RÂ²: 0.5745\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.8244\n",
      "  Val RÂ²: 0.6079\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.8056\n",
      "  Val RÂ²: 0.6609\n",
      "\n",
      "Target 5 Average:\n",
      "  Avg Train RÂ²: 0.8186\n",
      "  Avg Val RÂ²: 0.6310\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create indices and shuffle once\n",
    "lst = list(range(len(embeds)))\n",
    "random.seed(42)\n",
    "random.shuffle(lst)\n",
    "\n",
    "# Create multiple random 80/20 splits\n",
    "n_splits = 5\n",
    "splits = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    # Reshuffle for each split while maintaining same splits across targets\n",
    "    temp_lst = lst.copy()\n",
    "    random.seed(42 + i)  # Different seed for each split\n",
    "    random.shuffle(temp_lst)\n",
    "    \n",
    "    split_point = int(len(temp_lst) * 0.8)\n",
    "    train_idxs = temp_lst[:split_point]\n",
    "    val_idxs = temp_lst[split_point:]\n",
    "    splits.append((train_idxs, val_idxs))\n",
    "\n",
    "# Convert embeds to numpy array once for efficiency\n",
    "embeds_np = np.array(torch.cat(embeds))\n",
    "regressors = [[None for i in range(5)] for j in range(5)]\n",
    "# Now iterate through each target\n",
    "for i in range(5):\n",
    "    print(f\"\\n=== Target {i+1} ===\")\n",
    "    targets_np = np.array(torch.cat(targets[i]))\n",
    "    \n",
    "    split_scores = []\n",
    "    \n",
    "    for split_idx, (train_idxs, val_idxs) in enumerate(splits):\n",
    "        print(f\"Fold {split_idx+1}:\")\n",
    "        X_train, y_train = embeds_np[train_idxs], targets_np[train_idxs]\n",
    "        X_val, y_val = embeds_np[val_idxs], targets_np[val_idxs]\n",
    "        reg = Lasso()\n",
    "        reg.fit(X_train, y_train)\n",
    "        train_preds = reg.predict(X_train)\n",
    "        train_preds[train_preds < 0.0] = 0.0\n",
    "        train_r2 = r2_score(y_train, train_preds)\n",
    "        val_preds = reg.predict(X_val)\n",
    "        val_preds[val_preds < 0.0] = 0.0\n",
    "        val_r2 = r2_score(y_val, val_preds)\n",
    "        print(f\"  Train RÂ²: {train_r2:.4f}\")\n",
    "        print(f\"  Val RÂ²: {val_r2:.4f}\")\n",
    "        split_scores.append((train_r2, val_r2))\n",
    "        regressors[i][split_idx] = reg\n",
    "    \n",
    "    # Print summary for this target\n",
    "    avg_train_r2 = np.mean([score[0] for score in split_scores])\n",
    "    avg_val_r2 = np.mean([score[1] for score in split_scores])\n",
    "    print(f\"\\nTarget {i+1} Average:\")\n",
    "    print(f\"  Avg Train RÂ²: {avg_train_r2:.4f}\")\n",
    "    print(f\"  Avg Val RÂ²: {avg_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f68091a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:21.783943Z",
     "iopub.status.busy": "2025-11-02T12:22:21.783436Z",
     "iopub.status.idle": "2025-11-02T12:22:21.787236Z",
     "shell.execute_reply": "2025-11-02T12:22:21.786541Z"
    },
    "papermill": {
     "duration": 0.011594,
     "end_time": "2025-11-02T12:22:21.788245",
     "exception": false,
     "start_time": "2025-11-02T12:22:21.776651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = {\"Dry_Clover_g\": 0, \"Dry_Dead_g\": 1, \"Dry_Green_g\": 2, \"Dry_Total_g\": 3, \"GDM_g\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21127f56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:21.800233Z",
     "iopub.status.busy": "2025-11-02T12:22:21.800053Z",
     "iopub.status.idle": "2025-11-02T12:22:22.463334Z",
     "shell.execute_reply": "2025-11-02T12:22:22.462748Z"
    },
    "papermill": {
     "duration": 0.670804,
     "end_time": "2025-11-02T12:22:22.464655",
     "exception": false,
     "start_time": "2025-11-02T12:22:21.793851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_embeds = {}\n",
    "counter = 0\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std)])\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "root = \"/kaggle/input/csiro-biomass/\"\n",
    "sample_ids = []\n",
    "for i in range(len(test_df)):\n",
    "    entry = test_df.iloc[i]\n",
    "    file_path = root + entry['image_path']\n",
    "    sample_id = entry['sample_id']\n",
    "    #y = torch.tensor([[entry['target']]])\n",
    "    if sample_id not in sample_ids:\n",
    "        img = Image.open(file_path)\n",
    "        x = torch.tensor(processor(img).pixel_values)\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            test_embeds[sample_id.split(\"_\")[0]] = model(x).pooler_output.cpu()\n",
    "            counter += 1\n",
    "        sample_ids.append(sample_id)\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"{counter} batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3decd50a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:22.477461Z",
     "iopub.status.busy": "2025-11-02T12:22:22.477043Z",
     "iopub.status.idle": "2025-11-02T12:22:22.487073Z",
     "shell.execute_reply": "2025-11-02T12:22:22.486089Z"
    },
    "papermill": {
     "duration": 0.017329,
     "end_time": "2025-11-02T12:22:22.488139",
     "exception": false,
     "start_time": "2025-11-02T12:22:22.470810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "sample_ids = []\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "for i in range(len(test_df)):\n",
    "    try:\n",
    "        entry = test_df.iloc[i]\n",
    "        X = np.array(test_embeds[entry['sample_id'].split(\"__\")[0]])\n",
    "        sample_ids.append(entry['sample_id'])\n",
    "        models = regressors[mapping[entry['sample_id'].split(\"__\")[1]]]\n",
    "        prediction = 0.0\n",
    "        for item in models:\n",
    "            single_pred = item.predict(X)\n",
    "            if single_pred < 0.0:\n",
    "                single_pred = 0.0\n",
    "            prediction += single_pred\n",
    "        prediction = prediction / 5\n",
    "        predictions.append(float(prediction))\n",
    "    except Exception as e:\n",
    "        predictions.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1de628d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:22.500617Z",
     "iopub.status.busy": "2025-11-02T12:22:22.500394Z",
     "iopub.status.idle": "2025-11-02T12:22:22.516019Z",
     "shell.execute_reply": "2025-11-02T12:22:22.515391Z"
    },
    "papermill": {
     "duration": 0.023134,
     "end_time": "2025-11-02T12:22:22.516978",
     "exception": false,
     "start_time": "2025-11-02T12:22:22.493844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>1.975962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>22.272205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>31.084351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>55.230522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>28.500412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id     target\n",
       "0  ID1001187975__Dry_Clover_g   1.975962\n",
       "1    ID1001187975__Dry_Dead_g  22.272205\n",
       "2   ID1001187975__Dry_Green_g  31.084351\n",
       "3   ID1001187975__Dry_Total_g  55.230522\n",
       "4         ID1001187975__GDM_g  28.500412"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': sample_ids,\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission2.csv', index=False)\n",
    "submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9c1ca",
   "metadata": {
    "papermill": {
     "duration": 0.005598,
     "end_time": "2025-11-02T12:22:22.528385",
     "exception": false,
     "start_time": "2025-11-02T12:22:22.522787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3145261c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:22.541648Z",
     "iopub.status.busy": "2025-11-02T12:22:22.541432Z",
     "iopub.status.idle": "2025-11-02T12:22:22.698833Z",
     "shell.execute_reply": "2025-11-02T12:22:22.698089Z"
    },
    "papermill": {
     "duration": 0.164744,
     "end_time": "2025-11-02T12:22:22.699902",
     "exception": false,
     "start_time": "2025-11-02T12:22:22.535158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from PIL import Image\n",
    "!cp -r \"/kaggle/input/rsna-models/facebookresearch_dinov2_main (1)/root/.cache/torch/hub/facebookresearch_dinov2_main\" /kaggle/working/dinov2\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b510de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:22.713233Z",
     "iopub.status.busy": "2025-11-02T12:22:22.712714Z",
     "iopub.status.idle": "2025-11-02T12:22:55.266393Z",
     "shell.execute_reply": "2025-11-02T12:22:55.265766Z"
    },
    "papermill": {
     "duration": 32.561823,
     "end_time": "2025-11-02T12:22:55.267897",
     "exception": false,
     "start_time": "2025-11-02T12:22:22.706074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/giant/1')\n",
    "model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/giant/1')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b122de24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:22:55.281694Z",
     "iopub.status.busy": "2025-11-02T12:22:55.281059Z",
     "iopub.status.idle": "2025-11-02T12:25:08.500675Z",
     "shell.execute_reply": "2025-11-02T12:25:08.499816Z"
    },
    "papermill": {
     "duration": 133.227734,
     "end_time": "2025-11-02T12:25:08.502174",
     "exception": false,
     "start_time": "2025-11-02T12:22:55.274440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 batches processed.\n",
      "200 batches processed.\n",
      "300 batches processed.\n"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "targets = [[] for i in range(5)]\n",
    "counter = 0\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "#transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std)])\n",
    "train_df = pd.read_csv(\"/kaggle/input/csiro-biomass/train.csv\")\n",
    "root = \"/kaggle/input/csiro-biomass/\"\n",
    "for i in range(len(train_df)):\n",
    "    entry = train_df.iloc[i]\n",
    "    file_path = root + entry['image_path']\n",
    "    y = torch.tensor([[entry['target']]])\n",
    "    targets[i % 5].append(y)\n",
    "    if i % 5 == 0:\n",
    "        img = Image.open(file_path)\n",
    "        x = torch.tensor(processor(img).pixel_values)\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            embeds.append(model(x).pooler_output.cpu())\n",
    "            counter += 1\n",
    "            if counter % 100 == 0:\n",
    "                print(f\"{counter} batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3919d52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:25:08.516075Z",
     "iopub.status.busy": "2025-11-02T12:25:08.515841Z",
     "iopub.status.idle": "2025-11-02T12:25:09.286168Z",
     "shell.execute_reply": "2025-11-02T12:25:09.285248Z"
    },
    "papermill": {
     "duration": 0.778893,
     "end_time": "2025-11-02T12:25:09.287611",
     "exception": false,
     "start_time": "2025-11-02T12:25:08.508718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target 1 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.6838\n",
      "  Val RÂ²: 0.4291\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.6404\n",
      "  Val RÂ²: 0.6706\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.6436\n",
      "  Val RÂ²: 0.6398\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.6566\n",
      "  Val RÂ²: 0.4936\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.6574\n",
      "  Val RÂ²: 0.4737\n",
      "\n",
      "Target 1 Average:\n",
      "  Avg Train RÂ²: 0.6564\n",
      "  Avg Val RÂ²: 0.5414\n",
      "\n",
      "=== Target 2 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.5108\n",
      "  Val RÂ²: 0.4203\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.5131\n",
      "  Val RÂ²: 0.2292\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.5293\n",
      "  Val RÂ²: 0.2681\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.5390\n",
      "  Val RÂ²: 0.3578\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.5000\n",
      "  Val RÂ²: 0.4915\n",
      "\n",
      "Target 2 Average:\n",
      "  Avg Train RÂ²: 0.5185\n",
      "  Avg Val RÂ²: 0.3534\n",
      "\n",
      "=== Target 3 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.8203\n",
      "  Val RÂ²: 0.6847\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.8169\n",
      "  Val RÂ²: 0.6423\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.8198\n",
      "  Val RÂ²: 0.6231\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.8222\n",
      "  Val RÂ²: 0.5679\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.8234\n",
      "  Val RÂ²: 0.6318\n",
      "\n",
      "Target 3 Average:\n",
      "  Avg Train RÂ²: 0.8205\n",
      "  Avg Val RÂ²: 0.6300\n",
      "\n",
      "=== Target 4 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.7723\n",
      "  Val RÂ²: 0.5833\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.7870\n",
      "  Val RÂ²: 0.4525\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.7682\n",
      "  Val RÂ²: 0.5919\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.7721\n",
      "  Val RÂ²: 0.5033\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.7699\n",
      "  Val RÂ²: 0.5730\n",
      "\n",
      "Target 4 Average:\n",
      "  Avg Train RÂ²: 0.7739\n",
      "  Avg Val RÂ²: 0.5408\n",
      "\n",
      "=== Target 5 ===\n",
      "Fold 1:\n",
      "  Train RÂ²: 0.8067\n",
      "  Val RÂ²: 0.6363\n",
      "Fold 2:\n",
      "  Train RÂ²: 0.8019\n",
      "  Val RÂ²: 0.6218\n",
      "Fold 3:\n",
      "  Train RÂ²: 0.7996\n",
      "  Val RÂ²: 0.5873\n",
      "Fold 4:\n",
      "  Train RÂ²: 0.8117\n",
      "  Val RÂ²: 0.5244\n",
      "Fold 5:\n",
      "  Train RÂ²: 0.8109\n",
      "  Val RÂ²: 0.6017\n",
      "\n",
      "Target 5 Average:\n",
      "  Avg Train RÂ²: 0.8062\n",
      "  Avg Val RÂ²: 0.5943\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Create indices and shuffle once\n",
    "lst = list(range(len(embeds)))\n",
    "random.seed(42)\n",
    "random.shuffle(lst)\n",
    "\n",
    "# Create multiple random 80/20 splits\n",
    "n_splits = 5\n",
    "splits = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    # Reshuffle for each split while maintaining same splits across targets\n",
    "    temp_lst = lst.copy()\n",
    "    random.seed(42 + i)  # Different seed for each split\n",
    "    random.shuffle(temp_lst)\n",
    "    \n",
    "    split_point = int(len(temp_lst) * 0.8)\n",
    "    train_idxs = temp_lst[:split_point]\n",
    "    val_idxs = temp_lst[split_point:]\n",
    "    splits.append((train_idxs, val_idxs))\n",
    "\n",
    "# Convert embeds to numpy array once for efficiency\n",
    "embeds_np = np.array(torch.cat(embeds))\n",
    "regressors = [[None for i in range(5)] for j in range(5)]\n",
    "# Now iterate through each target\n",
    "for i in range(5):\n",
    "    print(f\"\\n=== Target {i+1} ===\")\n",
    "    targets_np = np.array(torch.cat(targets[i]))\n",
    "    \n",
    "    split_scores = []\n",
    "    \n",
    "    for split_idx, (train_idxs, val_idxs) in enumerate(splits):\n",
    "        print(f\"Fold {split_idx+1}:\")\n",
    "        X_train, y_train = embeds_np[train_idxs], targets_np[train_idxs]\n",
    "        X_val, y_val = embeds_np[val_idxs], targets_np[val_idxs]\n",
    "        reg = Lasso()\n",
    "        reg.fit(X_train, y_train)\n",
    "        train_preds = reg.predict(X_train)\n",
    "        train_preds[train_preds < 0.0] = 0.0\n",
    "        train_r2 = r2_score(y_train, train_preds)\n",
    "        val_preds = reg.predict(X_val)\n",
    "        val_preds[val_preds < 0.0] = 0.0\n",
    "        val_r2 = r2_score(y_val, val_preds)\n",
    "        print(f\"  Train RÂ²: {train_r2:.4f}\")\n",
    "        print(f\"  Val RÂ²: {val_r2:.4f}\")\n",
    "        split_scores.append((train_r2, val_r2))\n",
    "        regressors[i][split_idx] = reg\n",
    "    \n",
    "    # Print summary for this target\n",
    "    avg_train_r2 = np.mean([score[0] for score in split_scores])\n",
    "    avg_val_r2 = np.mean([score[1] for score in split_scores])\n",
    "    print(f\"\\nTarget {i+1} Average:\")\n",
    "    print(f\"  Avg Train RÂ²: {avg_train_r2:.4f}\")\n",
    "    print(f\"  Avg Val RÂ²: {avg_val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d9b9c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:25:09.303883Z",
     "iopub.status.busy": "2025-11-02T12:25:09.303625Z",
     "iopub.status.idle": "2025-11-02T12:25:09.307294Z",
     "shell.execute_reply": "2025-11-02T12:25:09.306608Z"
    },
    "papermill": {
     "duration": 0.012276,
     "end_time": "2025-11-02T12:25:09.308389",
     "exception": false,
     "start_time": "2025-11-02T12:25:09.296113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping = {\"Dry_Clover_g\": 0, \"Dry_Dead_g\": 1, \"Dry_Green_g\": 2, \"Dry_Total_g\": 3, \"GDM_g\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f240b8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:25:09.322116Z",
     "iopub.status.busy": "2025-11-02T12:25:09.321767Z",
     "iopub.status.idle": "2025-11-02T12:25:11.229322Z",
     "shell.execute_reply": "2025-11-02T12:25:11.228720Z"
    },
    "papermill": {
     "duration": 1.915726,
     "end_time": "2025-11-02T12:25:11.230609",
     "exception": false,
     "start_time": "2025-11-02T12:25:09.314883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_embeds = {}\n",
    "counter = 0\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224, 224)), transforms.Normalize(mean, std)])\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "root = \"/kaggle/input/csiro-biomass/\"\n",
    "sample_ids = []\n",
    "for i in range(len(test_df)):\n",
    "    entry = test_df.iloc[i]\n",
    "    file_path = root + entry['image_path']\n",
    "    sample_id = entry['sample_id']\n",
    "    #y = torch.tensor([[entry['target']]])\n",
    "    if sample_id not in sample_ids:\n",
    "        img = Image.open(file_path)\n",
    "        x = torch.tensor(processor(img).pixel_values)\n",
    "        with torch.no_grad():\n",
    "            x = x.cuda()\n",
    "            test_embeds[sample_id.split(\"_\")[0]] = model(x).pooler_output.cpu()\n",
    "            counter += 1\n",
    "        sample_ids.append(sample_id)\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"{counter} batches processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "136ed7e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:25:11.245204Z",
     "iopub.status.busy": "2025-11-02T12:25:11.244495Z",
     "iopub.status.idle": "2025-11-02T12:25:11.255096Z",
     "shell.execute_reply": "2025-11-02T12:25:11.254277Z"
    },
    "papermill": {
     "duration": 0.018754,
     "end_time": "2025-11-02T12:25:11.256122",
     "exception": false,
     "start_time": "2025-11-02T12:25:11.237368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n",
      "/tmp/ipykernel_19/131700968.py:17: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predictions.append(float(prediction))\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "sample_ids = []\n",
    "test_df = pd.read_csv(\"/kaggle/input/csiro-biomass/test.csv\")\n",
    "for i in range(len(test_df)):\n",
    "    try:\n",
    "        entry = test_df.iloc[i]\n",
    "        X = np.array(test_embeds[entry['sample_id'].split(\"__\")[0]])\n",
    "        sample_ids.append(entry['sample_id'])\n",
    "        models = regressors[mapping[entry['sample_id'].split(\"__\")[1]]]\n",
    "        prediction = 0.0\n",
    "        for item in models:\n",
    "            single_pred = item.predict(X)\n",
    "            if single_pred < 0.0:\n",
    "                single_pred = 0.0\n",
    "            prediction += single_pred\n",
    "        prediction = prediction / 5\n",
    "        predictions.append(float(prediction))\n",
    "    except Exception as e:\n",
    "        predictions.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7a10606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T12:25:11.269910Z",
     "iopub.status.busy": "2025-11-02T12:25:11.269706Z",
     "iopub.status.idle": "2025-11-02T12:25:11.287969Z",
     "shell.execute_reply": "2025-11-02T12:25:11.287358Z"
    },
    "papermill": {
     "duration": 0.026476,
     "end_time": "2025-11-02T12:25:11.289094",
     "exception": false,
     "start_time": "2025-11-02T12:25:11.262618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID1001187975__Dry_Clover_g</th>\n",
       "      <td>1.750975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1001187975__Dry_Dead_g</th>\n",
       "      <td>22.623624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1001187975__Dry_Green_g</th>\n",
       "      <td>27.746390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1001187975__Dry_Total_g</th>\n",
       "      <td>48.613687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID1001187975__GDM_g</th>\n",
       "      <td>28.878895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               target\n",
       "sample_id                            \n",
       "ID1001187975__Dry_Clover_g   1.750975\n",
       "ID1001187975__Dry_Dead_g    22.623624\n",
       "ID1001187975__Dry_Green_g   27.746390\n",
       "ID1001187975__Dry_Total_g   48.613687\n",
       "ID1001187975__GDM_g         28.878895"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /kaggle/working\n",
    "submission = pd.DataFrame({\n",
    "    'sample_id': sample_ids,\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission_giant.csv', index=False)\n",
    "submission\n",
    "df1 = pd.read_csv(\"/kaggle/working/submission1.csv\").set_index(\"sample_id\")\n",
    "df2 = pd.read_csv(\"/kaggle/working/submission2.csv\").set_index(\"sample_id\")\n",
    "df3 = pd.read_csv(\"/kaggle/working/submission.csv\").set_index(\"sample_id\")\n",
    "df4 = pd.read_csv(\"/kaggle/working/submission_giant.csv\").set_index(\"sample_id\")\n",
    "df = .55*(.05*df1 + .55*df2 + .4*df3) + .45*df4\n",
    "df.to_csv(\"submission.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9bd612",
   "metadata": {
    "papermill": {
     "duration": 0.007219,
     "end_time": "2025-11-02T12:25:11.303430",
     "exception": false,
     "start_time": "2025-11-02T12:25:11.296211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 8620094,
     "sourceId": 13569643,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 272104372,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 986,
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 986,
     "modelInstanceId": 3329,
     "sourceId": 4537,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 317.014592,
   "end_time": "2025-11-02T12:25:14.364462",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-02T12:19:57.349870",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
